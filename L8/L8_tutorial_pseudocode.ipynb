{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tutorial 8: SBM and DC-SBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='magneta'> In this tutorial, we will implement various inference techniques and models to solve the SBM on real networks. We will use several codes developed in the package pysbm. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clone the github repository pysbm at https://github.com/funket/pysbm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the datasets of American College football *(football)*, Zacharyâ€™s karate club *(karate)* and Political blogs *(polblogs)* from http://www-personal.umich.edu/~mejn/netdata/ and put them inside the folder pysbm/Network Data/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to import the `pysbm` package and the `networkx` package, \n",
    "which is the used package for representing the networks. \n",
    "Additionally, we want to handle ```numpy``` structures and create some plots with `matplotlib`. \n",
    "\n",
    "If you later want to process larger graphs, we recommend using [PyPy](https://pypy.org). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'karate':'./pysbm/Network Data/karate/karate.gml',\n",
    "           'football':'./pysbm/Network Data/football/football.gml',\n",
    "           'polblogs':'./pysbm/Network Data/polblogs/polblogs.gml'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0:'b',1:'r',2:'g',3:'orange',4:'black',5:'magenta'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with one of the standard examples, the karate club network.\n",
    "\n",
    "* Import dataset into a `networkx` network object. Make it `undirected` as we are interested in studying, for simplicity, only this version.   \n",
    "Keep only the largest connected component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: import the dataset karate_club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: replicate the example of Karrer and Newmann 2011 \n",
    "(https://journals.aps.org/pre/pdf/10.1103/PhysRevE.83.016107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's infer stochastic block models for the karate club graph with the standard  SBM. First, we need the graph and encapsulate the graph into a `partition` object with the known number of blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "standard_partition = # Your code here\n",
    "standard_objective_function = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at the current state and plot the nodes with size proportional to their degree and with color equivalent to the group they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = # Your code here\n",
    "position = # Your code here\n",
    "\n",
    "plt.figure()\n",
    "nx.draw_networkx_nodes(# Your code here)\n",
    "nx.draw_networkx_edges(# Your code here)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run 3 different inference methods:\n",
    "   * `KarrerInference`: the greedy with MC moves proposed by Karrer & Newman to find the maximum of the objective function.\n",
    "   * `MetropolisHastingInference`: a Metropolis Hasting MC scheme similar to Karrer & Newman but where there is an acceptance rate to a move. The Karrer & Newman instead, makes deterministic moves that always improve the objective function. \n",
    "   * `PeixotoInference`: a Metropolis Hasting MC scheme wich aggregates blocks, in addition to switching single nodes' groups. This is similar to `MetropolisHastingInference` but in addition merges blocks while performing moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the three methods will end up in a local minimum of the objective function. Therefore we run the inference 10 times and keep the partition associated to the best value of the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 1**: `KarrerInference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard=None\n",
    "for r in range(N_real):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 1b**: `KarrerInference` with no negative moves allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_nn=None\n",
    "for r in range(N_real):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 2**: `MetropolisHastingInference` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_MH=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 3**: `PeixotoInference` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_Peixoto=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_colors(colors, partition, graph):\n",
    "    # Your code here \n",
    "    \n",
    "    return node_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [best_partition_standard, best_partition_standard_nn, best_partition_standard_MH, best_partition_standard_Peixoto]\n",
    "labels = ['Greedy', 'Greedy Non-Negative', 'MH', 'Peixoto']\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "for i, p in enumerate(models):\n",
    "    # Your code here \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_groups(partition,graph,K=None):\n",
    "    # Your code here  \n",
    "    \n",
    "    return groups\n",
    "\n",
    "def ordered_nodelist(partition,graph,K=None):\n",
    "    # Your code here \n",
    "\n",
    "    return ordered_nodelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the adjacency matrix ordered by blocks and compare it with the unordered one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (unordered one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i, p in enumerate(models):\n",
    "    # Your code here \n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the affinity matrices of two partition at your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree-corrected SBM\n",
    "\n",
    "As you could notice, the best partition found by the algorithms favor a block division correlated with degree.   The solution to this problem is to incorporate explicitly degree heterogeneity into the model. \n",
    "\n",
    "This implies introducing new hidden variables $\\theta_{i}\\in \\mathbb{R}\\geq 0$ controlling the expected degree of node $i$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "P(\\mathbf{A}| \\theta)&=& \\prod_{i<j} \\text{Pois} \\,(A_{ij};\\theta_{i}\\theta_{j}\\,C_{q_i q_j} ) \\\\\n",
    "&=& \\prod_{i<j} \\frac{e^{-\\theta_{i}\\theta_{j}\\,C_{q_iq_j}}\\, (\\theta_{i}\\theta_{j}\\,C_{q_iq_j})^{A_{ij}}}{A_{ij}!} \\quad.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_corrected_objective_function = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the three previous inference methods, but this time using the degree-corrected likelihood as objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 1**: `KarrerInference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_DC=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 1b**: `KarrerInference` with no negative moves allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_nn_DC=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 2**: `MetropolisHastingInference` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_MH_DC=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference 3**: `PeixotoInference` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_real=10\n",
    "best_objective=-1000000\n",
    "best_partition_standard_Peixoto_DC=None\n",
    "for r in range(N_real):\n",
    "    # Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_DC = [best_partition_standard_DC, best_partition_standard_nn_DC, best_partition_standard_MH_DC, best_partition_standard_Peixoto_DC]\n",
    "plt.figure(figsize=(16,10))\n",
    "for i, p in enumerate(models_DC):\n",
    "    # Your code here \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the adjacency matrix ordered by blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i, p in enumerate(models_DC):\n",
    "    # Your code here \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the affinity matrices of two partition at your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
