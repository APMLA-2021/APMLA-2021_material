{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior sampling for Gaussian Mixture Model using Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "import importlib\n",
    "import GMM_gibbs as gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(zs,K,X,title):\n",
    "    fig, ax = plt.subplots()\n",
    "    datasets = []\n",
    "    for i in range(K):\n",
    "        # Assigned indices\n",
    "        assigned_indices = (zs == i)\n",
    "        datasets.append(X[assigned_indices, :])\n",
    "\n",
    "    # Now let's put the scatter plots onto the scene.\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "    for j,data in enumerate(datasets):\n",
    "        ax.scatter(data[:, 0], data[:, 1], color=colors[j])\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_logprob(iter_prob):\n",
    "    fig, ax = plt.subplots()\n",
    "    iteration_vec = range(0, len(iter_prob))\n",
    "    ax.plot(iteration_vec, iter_prob)\n",
    "    ax.set_title('Log Probability vs. Iterations')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data():\n",
    "    \"\"\" This is the a test script used for me to generate test data\"\"\"\n",
    "    # All of these will be assumed 2-D data\n",
    "    # Let's generate a mixture of three gaussians\n",
    "    u_0 = np.array([-2.0,-2.0])\n",
    "    u_1 = np.array([0.0,2.0])\n",
    "    u_2 = np.array([2.0,-2.0])\n",
    "\n",
    "    # sigmas for each of the data\n",
    "    sigmas = [1, 1, 1]\n",
    "    points_per_cluster = 100\n",
    "\n",
    "    # Now initialize the data variables\n",
    "    data0 = np.random.randn(points_per_cluster,2)*sigmas[0] + u_0\n",
    "    data1 = np.random.randn(points_per_cluster,2)*sigmas[1] + u_1\n",
    "    data2 = np.random.randn(points_per_cluster,2)*sigmas[2] + u_2\n",
    "    X = np.vstack((data0, data1, data2))\n",
    "\n",
    "    # Now random init the cluster assignments\n",
    "    rand_Y = np.random.randint(0, 3, points_per_cluster*3)\n",
    "    return X, rand_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1\n",
    "- Sample mixture locations $\\mu_k$ \n",
    "- Sample mixing coefficents $\\pi_k$\n",
    "- Sample cluster assignements $z_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "N = X.shape[0]\n",
    "\n",
    "# GMM params\n",
    "mus = np.array([np.random.rand() * np.ones(X.shape[1]) for k in range(K)])\n",
    "# mus = np.array([1 * np.ones(K), 15 * np.ones(K)], dtype='float')\n",
    "sigmas = np.array([np.diag(np.ones(X.shape[1])) for k in range(K)], dtype='float')\n",
    "lambdas = np.array([np.linalg.inv(sigmas[k]) for k in range(K)])\n",
    "# pis = np.array(0.5 * np.ones(K) )  # Mixing probs.\n",
    "pis = np.ones(K)/ float(K)\n",
    "zs = np.zeros([N])  # Assignments\n",
    "for i in range(N):\n",
    "    z = np.random.multinomial(n=N, pvals=pis).argmax()\n",
    "    zs[i] = z\n",
    "Y = zs.copy()\n",
    "# Priors\n",
    "alpha =np.ones(K)\n",
    "pis = np.random.dirichlet(alpha)\n",
    "mus0 = np.ones((K, X.shape[1]))\n",
    "sigmas0 = np.array([np.diag(np.ones(X.shape[1])) for k in range(K)], dtype='float')\n",
    "lambdas0 = np.array([np.linalg.inv(sigmas0[k]) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points(zs,K,X,title = 'Initial assignement')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "normalizer = (1 / ((sigma ** 2) * np.sqrt(2 * np.pi)))\n",
    "iter_prob = []\n",
    "T = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(T):\n",
    "    # Sample from full conditional of assignment\n",
    "    # z ~ p(z) \\propto pi*N(y|pi)\n",
    "    probs = np.zeros([N, K])\n",
    "\n",
    "    for k in range(K):\n",
    "        p = pis[k] * st.multivariate_normal.pdf(X, mean=mus[k], cov=sigmas[k])\n",
    "        probs[:, k] = p\n",
    "\n",
    "    # Normalize\n",
    "    probs /= np.sum(probs, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # For each data point, draw the cluster assignment\n",
    "    for i in range(N):\n",
    "        z = np.random.multinomial(n=1, pvals=probs[i]).argmax()\n",
    "        zs[i] = z\n",
    "\n",
    "    # Sample from full conditional of cluster parameter\n",
    "    # Assume fixed covariance => posterior is Normal\n",
    "    # mu ~ N(mu, sigma)\n",
    "    Ns = np.zeros(K, dtype='int')\n",
    "\n",
    "    for k in range(K):\n",
    "        # Gather all data points assigned to cluster k\n",
    "        Xk = X[zs == k]\n",
    "        Ns[k] = Xk.shape[0]\n",
    "\n",
    "        # Covariance of posterior\n",
    "        lambda_post = lambdas0[k] + Ns[k]*lambdas[k]\n",
    "        cov_post = np.linalg.inv(lambda_post)\n",
    "\n",
    "        # Mean of posterior\n",
    "        left = cov_post\n",
    "        right = lambdas0[k] @ mus0[k] + Ns[k]*lambdas[k] @ np.mean(Xk, axis=0)\n",
    "        mus_post = left @ right\n",
    "\n",
    "        # Draw new mean sample from posterior\n",
    "        mus[k] = st.multivariate_normal.rvs(mus_post, cov_post)\n",
    "\n",
    "    # Sample from full conditional of the mixing weight\n",
    "    # pi ~ Dir(alpha + n)\n",
    "    pis = np.random.dirichlet(alpha + Ns)\n",
    "    \n",
    "    # Calculate log-likelihood\n",
    "    log_probs = np.zeros(X.shape[0])\n",
    "    for i in range(0, X.shape[0]):\n",
    "       # Calculate the sum of the lob probabilities\n",
    "        clust = int(zs[i])\n",
    "        d = np.linalg.norm(X[i, :] - mus[clust, :])\n",
    "        log_probs[i] =  np.log(np.exp(-(d ** 2) / (2 * (sigma ** 2))) * normalizer)\n",
    "\n",
    "    iter_prob.append(log_probs.sum())\n",
    "\n",
    "for k in range(K):\n",
    "    print('{} data in cluster-{}, mean: {}'.format(Ns[k], k, mus[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points(zs,K,X,title = 'Final mixture assignement algorithm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logprob(iter_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2: collapse $\\pi$\n",
    "- Sample mixture locations $\\mu_k$ \n",
    "- Sample cluster assignement $z_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gmm.MixGaussGibbsSampler(X, zs.astype('int'),sigma=1, lam=1, burn_in=50, lag=10)\n",
    "gs.perform_gibbs_sampling(iterations=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare mus algo1 and algo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.u_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    print(mus[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
